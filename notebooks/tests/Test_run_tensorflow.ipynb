{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import os\n",
    "import scipy.misc\n",
    "import sys\n",
    "import glob\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, decomposition, manifold, preprocessing\n",
    "\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = \"/usr/local/featureExtractionParty/external/pointnet_spine_ae\"\n",
    "sys.path.insert(0,currentdir) \n",
    "import provider\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_POINT = 2048\n",
    "MODEL_PATH = '/usr/local/featureExtractionParty/external/pointnet_spine_ae/log_model_manually_selected_trainingset_40_aligned/best_model_epoch_009.ckpt'\n",
    "GPU_INDEX = 0\n",
    "MODEL = importlib.import_module('models.model') # import network module\n",
    "DUMP_DIR = 'dump'\n",
    "if not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\n",
    "LOG_FOUT = open(os.path.join(DUMP_DIR, 'log_evaluate.txt'), 'w')\n",
    "HOSTNAME = socket.gethostname()\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "    \n",
    "\n",
    "def evaluate(FILES, num_votes):\n",
    "    is_training = False\n",
    "     \n",
    "    with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "        \n",
    "        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "        print(pointclouds_pl.shape)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "        labels_pl_rep = tf.placeholder(tf.float32,shape=(1))\n",
    "\n",
    "        # simple model\n",
    "        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n",
    "        print(\"Size of embedding\")\n",
    "        print(pred.shape)\n",
    "        \n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    log_string(\"Model restored.\")\n",
    "\n",
    "    ops = {'pointclouds_pl': pointclouds_pl,\n",
    "           'labels_pl': labels_pl_rep,\n",
    "           'is_training_pl': is_training_pl,\n",
    "           'pred': pred,\n",
    "           'embedding': end_points['embedding']\n",
    "           }\n",
    "    eval_one_epoch(FILES, sess, ops, num_votes)\n",
    "    #features,files = eval_one_epoch(FILES, sess, ops, num_votes)\n",
    "    #features = np.array(features)\n",
    "    #return features,files\n",
    "    \n",
    "def eval_one_epoch(FILES, sess, ops, num_votes=1, topk=1):\n",
    "    features = []\n",
    "    filenames = []\n",
    "    \n",
    "    is_training = False\n",
    "    fout = open(os.path.join(DUMP_DIR, 'pred_label.txt'), 'w')\n",
    "    for fn in range(len(FILES)):\n",
    "        outfile = FILES[fn].replace(\".off\",\"_ae_model_manualV3.txt\")\n",
    "        if not os.path.exists(outfile):\n",
    "        #if 1 ==1:\n",
    "            log_string('----'+str(fn)+'----')\n",
    "            print(FILES[fn])\n",
    "            current_data, current_label = provider.loadAllOffDataFile(FILES[fn], NUM_POINT)\n",
    "            \n",
    "            if current_data is not None:\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data,\n",
    "                                     ops['labels_pl']: current_label,\n",
    "                                     ops['is_training_pl']: is_training}\n",
    "                pred_val = sess.run([ops['embedding']], feed_dict=feed_dict)\n",
    "                #pred_val = sess.run([ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                np.savetxt(outfile,np.squeeze(pred_val))\n",
    "                \n",
    "                print (outfile)\n",
    "                #features.append(np.squeeze(pred_val))\n",
    "    \n",
    "def loadfeatures(feat_files):\n",
    "    features = []\n",
    "    #synapse_distances = []\n",
    "    index = 0\n",
    "    for f in feat_files:\n",
    "        index += 1\n",
    "        v = np.loadtxt(f)\n",
    "        features.append(v)\n",
    "        #curdistfilename = f.replace('ae_model_v2.txt','distance.txt')\n",
    "        #synapse_distances.append(np.loadtxt(curdistfilename))\n",
    "    return features\n",
    "\n",
    "def dist2pt (features, pt):\n",
    "    features = np.array(features)\n",
    "    pt = np.array(pt)\n",
    "    dists = np.linalg.norm(features-pt[np.newaxis,:],axis=1) \n",
    "    return np.argmin(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
